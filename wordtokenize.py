from nltk.tokenize import word_tokenize
text=""
words=word_tokenize(sentence)
print(words)
